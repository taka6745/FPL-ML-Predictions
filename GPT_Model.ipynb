{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMkbCvqdHOlld8J9mr431TX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["##Part 1: Import Libraries and Unzip the Data"],"metadata":{"id":"AxQeQAQNAVqz"}},{"cell_type":"code","execution_count":9,"metadata":{"id":"ttuLqHq2zKAh","executionInfo":{"status":"ok","timestamp":1694096466078,"user_tz":-600,"elapsed":6,"user":{"displayName":"Takoda Mundy","userId":"10662830657133797315"}}},"outputs":[],"source":["# Import required libraries\n","import pandas as pd\n","import os\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestRegressor"]},{"cell_type":"markdown","source":["##Part 2: Load the Data"],"metadata":{"id":"njueKg5sAf_A"}},{"cell_type":"code","source":["# Load the game week data\n","gw_path = 'FPL/data/2023-24'  # Adjust this to the correct path where your 2023-24 game week data resides\n","gw_files = [f for f in os.listdir(gw_path) if os.path.isfile(os.path.join(gw_path, f))]\n","gw_dfs = [pd.read_csv(os.path.join(gw_path, f)) for f in gw_files]\n","merged_gw_df = pd.concat(gw_dfs, ignore_index=True)\n","\n","# Load the teams data\n","teams_2023_24_df = pd.read_csv('FPL/data/master_team_list.csv')  # Adjust this to the correct path where your teams data resides\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"vbSFp0gG797R","executionInfo":{"status":"error","timestamp":1694096515677,"user_tz":-600,"elapsed":85,"user":{"displayName":"Takoda Mundy","userId":"10662830657133797315"}},"outputId":"43d86067-7b32-4365-b4db-ad27fd751269"},"execution_count":13,"outputs":[{"output_type":"error","ename":"UnicodeDecodeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)","Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m gw_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFPL/data/2023-24\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Adjust this to the correct path where your 2023-24 game week data resides\u001b[39;00m\n\u001b[1;32m      3\u001b[0m gw_files \u001b[38;5;241m=\u001b[39m [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(gw_path) \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(gw_path, f))]\n\u001b[0;32m----> 4\u001b[0m gw_dfs \u001b[38;5;241m=\u001b[39m [pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(gw_path, f)) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m gw_files]\n\u001b[1;32m      5\u001b[0m merged_gw_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(gw_dfs, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Load the teams data\u001b[39;00m\n","Cell \u001b[0;32mIn[13], line 4\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m gw_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFPL/data/2023-24\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Adjust this to the correct path where your 2023-24 game week data resides\u001b[39;00m\n\u001b[1;32m      3\u001b[0m gw_files \u001b[38;5;241m=\u001b[39m [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(gw_path) \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(gw_path, f))]\n\u001b[0;32m----> 4\u001b[0m gw_dfs \u001b[38;5;241m=\u001b[39m [\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgw_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m gw_files]\n\u001b[1;32m      5\u001b[0m merged_gw_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(gw_dfs, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Load the teams data\u001b[39;00m\n","File \u001b[0;32m~/mambaforge/envs/tensyflow/lib/python3.9/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/mambaforge/envs/tensyflow/lib/python3.9/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n","File \u001b[0;32m~/mambaforge/envs/tensyflow/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/mambaforge/envs/tensyflow/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1679\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1676\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1678\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1679\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1680\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1681\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m~/mambaforge/envs/tensyflow/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py:93\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype_backend\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[43mparsers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTextReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n","File \u001b[0;32m~/mambaforge/envs/tensyflow/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:550\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m~/mambaforge/envs/tensyflow/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:639\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m~/mambaforge/envs/tensyflow/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:850\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m~/mambaforge/envs/tensyflow/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:861\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m~/mambaforge/envs/tensyflow/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:2021\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n","\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xff in position 1098: invalid start byte"]}]},{"cell_type":"markdown","source":["##Part 3: Data Preprocessing and Merge\n"],"metadata":{"id":"6_T162qQAi0S"}},{"cell_type":"code","source":["# Merge the game week data with the team data based on the 'team' column\n","merged_gw_df = pd.merge(merged_gw_df, teams_2023_24_df, left_on='team', right_on='id', how='left')\n","\n","# Fill missing 'form' values with zero\n","merged_gw_df['form'].fillna(0, inplace=True)\n"],"metadata":{"id":"QQXTVqIAAmqR","executionInfo":{"status":"aborted","timestamp":1694096466123,"user_tz":-600,"elapsed":61,"user":{"displayName":"Takoda Mundy","userId":"10662830657133797315"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","##Part 4: Feature Engineering - Rolling Averages and Lag Variables"],"metadata":{"id":"LZwTNgp5AoqV"}},{"cell_type":"code","source":["# Generate rolling averages and lag variables for key metrics\n","def generate_rolling_and_lag(df, column, window=3):\n","    df = df.sort_values(by=['name', 'GW'])\n","    df[f'{column}_rolling_avg_{window}'] = df.groupby('name')[column].transform(lambda x: x.rolling(window=window, min_periods=1).mean())\n","    df[f'{column}_lag_1'] = df.groupby('name')[column].shift(1)\n","    return df\n","\n","key_metrics = ['total_points', 'assists', 'goals_scored', 'minutes', 'bps']\n","for metric in key_metrics:\n","    merged_gw_df = generate_rolling_and_lag(merged_gw_df, metric)\n"],"metadata":{"id":"jXuTvvnBAsEk","executionInfo":{"status":"aborted","timestamp":1694096466131,"user_tz":-600,"elapsed":68,"user":{"displayName":"Takoda Mundy","userId":"10662830657133797315"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Part 5: Additional Features and One-Hot Encoding"],"metadata":{"id":"RAoPEa7gAwr_"}},{"cell_type":"code","source":["# Generate additional features\n","positional_strength_multiplier = merged_gw_df.groupby('position')['total_points'].transform('mean')\n","merged_gw_df['positional_strength'] = merged_gw_df['total_points'] * positional_strength_multiplier\n","merged_gw_df['player_team_interaction'] = merged_gw_df['total_points_rolling_avg_3'] * merged_gw_df['strength_overall_home']\n","merged_gw_df.fillna(0, inplace=True)\n","\n","# One-hot encode categorical variables\n","merged_gw_df_encoded = pd.get_dummies(merged_gw_df, columns=['position', 'team'], drop_first=True)"],"metadata":{"id":"Fw4j1z6PAv2H","executionInfo":{"status":"aborted","timestamp":1694096466132,"user_tz":-600,"elapsed":67,"user":{"displayName":"Takoda Mundy","userId":"10662830657133797315"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Part 6: Feature Selection Using Random Forest"],"metadata":{"id":"7hO_OEzFA0Zt"}},{"cell_type":"code","source":["# Identify non-numeric columns and remove them\n","non_numeric_columns = merged_gw_df_encoded.select_dtypes(include=['object']).columns.tolist()\n","X = merged_gw_df_encoded.drop(non_numeric_columns + ['total_points'], axis=1)\n","y = merged_gw_df_encoded['total_points']\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Initialize Random Forest Regressor for feature importance\n","rf = RandomForestRegressor(n_estimators=100, random_state=42)\n","rf.fit(X_train, y_train)\n","feature_importances = pd.DataFrame(rf.feature_importances_, index = X_train.columns, columns=['importance']).sort_values('importance', ascending=False)\n"],"metadata":{"id":"jyVs2Jy2A3FW","executionInfo":{"status":"aborted","timestamp":1694096466133,"user_tz":-600,"elapsed":68,"user":{"displayName":"Takoda Mundy","userId":"10662830657133797315"}}},"execution_count":null,"outputs":[]}]}